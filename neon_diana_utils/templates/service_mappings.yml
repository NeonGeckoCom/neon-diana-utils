# MQ Services
neon-rabbitmq:
  container_image: &image_rabbitmq rabbitmq:3-management
  container_name: &name_rabbitmq neon-rabbitmq
  service_class: mq-backend
  docker_compose:
    container_name: *name_rabbitmq
    image: *image_rabbitmq
    restart: always
    networks:
      - mq-backend
    labels:
      kompose.service.type: LoadBalancer
    ports:
      - 15672:15672
      - 5672:5672
    environment:
      - RABBITMQ_CONFIG_FILE=/config/rabbitmq.conf
    volumes:
      - config:/config

neon-api-proxy:
  container_image: &image_api_proxy ghcr.io/neongeckocom/neon_api_proxy:dev
  container_name: &name_api_proxy neon-api-proxy
  service_class: mq-backend
  mq:
    mq_service_name: neon_api_connector
    mq_username: neon_api
    mq_user_permissions:
      neon_api:
        /neon_api:
          read: .*
          write: .*
          configure: .*
      neon_api_utils:
        /neon_api:
          read: ./*
          write: ./*
          configure: ./*
    mq_vhosts:
    - /neon_api
  docker_compose:
    container_name: *name_api_proxy
    image: *image_api_proxy
    restart: always
    networks:
      - mq-backend
    labels:
      kompose.service.type: headless
    volumes:
      - config:/config
neon-brands-service:
  container_image: &image_brands_service ghcr.io/neongeckocom/neon_brands_service:dev
  container_name: &name_brands_service neon-brands-service
  service_class: mq-backend
  mq:
    mq_service_name: neon_coupon_connector
    mq_username: neon_coupons
    mq_user_permissions:
      neon_coupons:
        /neon_coupons:
          read: .*
          write: .*
          configure: .*
      neon_api_utils:
        /neon_coupons:
          read: .*
          write: .*
          configure: .*
    mq_vhosts:
    - /neon_coupons
  docker_compose:
    container_name: *name_brands_service
    image: *image_brands_service
    restart: always
    networks:
      - mq-backend
    labels:
      kompose.service.type: headless
    volumes:
      - config:/config
neon-email-proxy:
  container_image: &image_email_proxy ghcr.io/neongeckocom/neon_email_proxy:dev
  container_name: &name_email_proxy neon-email-proxy
  service_class: mq-backend
  mq:
    mq_service_name: neon_email_proxy
    mq_username: neon_email
    mq_user_permissions:
      neon_email:
        /neon_emails:
          read: .*
          write: .*
          configure: .*
      neon_api_utils:
        /neon_emails:
          read: "^(?!neon_emails_input).*"
          write: .*
          configure: .*
    mq_vhosts:
    - /neon_emails
  docker_compose:
    container_name: *name_email_proxy
    image: *image_email_proxy
    restart: always
    networks:
      - mq-backend
    labels:
      kompose.service.type: headless
    volumes:
      - config:/config
neon-script-parser:
  container_image: &image_script_parser ghcr.io/neongeckocom/neon-script-parser:dev
  container_name: &name_script_parser neon-script-parser
  service_class: mq-backend
  mq:
    mq_service_name: neon_script_parser_service
    mq_username: neon_script_parser
    mq_user_permissions:
      neon_script_parser:
        /neon_script_parser:
          read: .*
          write: .*
          configure: .*
      neon_api_utils:
        /neon_script_parser:
          read: .*
          write: .*
          configure: .*
    mq_vhosts:
    - /neon_script_parser
  docker_compose:
    container_name: *name_script_parser
    image: *image_script_parser
    restart: always
    networks:
      - mq-backend
    labels:
      kompose.service.type: headless
    volumes:
      - config:/config
neon-metrics-service:
  container_image: &image_metrics_service ghcr.io/neongeckocom/neon_metrics_service:dev
  container_name: &name_metrics_service neon-metrics-service
  service_class: mq-backend
  mq:
    mq_service_name: neon_metrics_connector
    mq_username: neon_metrics
    mq_user_permissions:
      neon_metrics:
        /neon_metrics:
          read: .*
          write: .*
          configure: .*
      neon_api_utils:
        /neon_metrics:
          read: ""
          write: .*
          configure: .*
    mq_vhosts:
    - /neon_metrics
  docker_compose:
    container_name: *name_metrics_service
    image: *image_metrics_service
    restart: always
    networks:
      - mq-backend
    labels:
      kompose.service.type: headless
    volumes:
      - config:/config
      - metrics:/metrics

# HTTP Services
tts-larynx:
  container_image: &image_larynx_server rhasspy/larynx:latest
  container_name: &name_larynx_server tts-larynx
  service_class: http-backend
  docker_compose:
    container_name: *name_larynx_server
    image: *image_larynx_server
    restart: always
    ports:
      - 5002:5002
tts-mozilla:
  container_image: &image_mozilla_tts synesthesiam/mozilla-tts
  container_name: &name_mozilla_tts tts-mozilla
  service_class: http-backend
  docker_compose:
    container_name: *name_mozilla_tts
    image: *image_mozilla_tts
    restart: always
    ports:
      - 15002:5002
tts-glados:
  container_image: &image_glados_tts ghcr.io/neongeckocom/neon-tts-plugin-glados:dev
  container_name: &name_glados_tts tts-glados
  service_class: http-backend
  docker_compose:
    container_name: *name_glados_tts
    image: *image_glados_tts
    restart: always
    ports:
      - 9666:9666
tts-mimic2-nancy:
  container_image: &image_mimic2_nancy_tts ghcr.io/openvoiceos/mimic2-nancy:dev
  container_name: &name_mimic2_nancy_tts tts-mimic2-nancy
  service_class: http-backend
  docker_compose:
    container_name: *name_mimic2_nancy_tts
    image: *image_mimic2_nancy_tts
    restart: always
    ports:
      - 9000:9000
tts-mimic2-ljspeech:
  container_image: &image_mimic2_ljspeech_tts ghcr.io/openvoiceos/mimic2-ljspeech:dev
  container_name: &name_mimic2_ljspeech_tts tts-mimic2-ljspeech
  service_class: http-backend
  docker_compose:
    container_name: *name_mimic2_ljspeech_tts
    image: *image_mimic2_ljspeech_tts
    restart: always
    ports:
      - 9001:9000
lang-libretranslate:
  container_image: &image_libretranslate libretranslate/libretranslate:main
  container_name: &name_libretranslate lang-libretranslate
  service_class: http-backend
  docker_compose:
    container_name: *name_libretranslate
    image: *image_libretranslate
    restart: always
    ports:
      - 5000:5000
ww-snowboy:
  container_image: &image_snowboy rhasspy/snowboy-seasalt
  container_name: &name_snowboy ww-snowboy
  service_class: http-backend
  docker_compose:
    container_name: *name_snowboy
    image: *image_snowboy
    restart: always
    ports:
      - 8000:8000
